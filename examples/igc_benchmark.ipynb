{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGC Benchmark\n",
    "\n",
    "In order to assess the relevancy of IGC attributions compared to other naive\n",
    "dataset-wise attribution methods, we propose synthetic experiments. We first\n",
    "define some localized image statistics computed on random images, and then try\n",
    "to recover the generating masks/rules from the pairs of original images and\n",
    "computed statistics. To make this procedure feasible, generated random images\n",
    "are designed to respect the spatial frequency distribution of natural images\n",
    "(i.e. having some spatial redundancy). For more details, look at the _Benchmark_\n",
    "section of the original IGC [paper](http://arxiv.org/abs/2404.13910).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGC from original localized image statistic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igcsimulation.simulation_1v0 import Dataset\n",
    "\n",
    "# Experiments A, B, C, D (mask_name, imst_name, imst_kwargs)\n",
    "expe = ('comb_01', 'w_sum', None)\n",
    "#expe = ('ccat_01', 'max_mean_bin', None)\n",
    "#expe = ('ccat_02', 'max_sim_rand00_bin', {'probs': (0.0, 0.5)})\n",
    "#expe = ('ccat_03', 'argmax_sim_rand01_bin', {'permute': True})\n",
    "\n",
    "img_size = 64\n",
    "n_samples = (1000, 1000)\n",
    "# n_samples = (100000, 100000)  # Paper's values\n",
    "fft_slope = -1.2  # for natural images\n",
    "\n",
    "dataset = Dataset(expe[0], expe[1], img_size, n_samples, fft_slope, expe[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igcsimulation.simulation_1v0 import Model\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "model = Model(dataset, model_name='sim_1v0_a100', device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute IGC attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.int_grad_corr(x_0=8, y_idx=0, n_steps=512, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute attributions with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.int_grad_auto_corr(x_0=8, y_idx=0, n_steps=512, batch_size=8)\n",
    "_ = model.int_grad_mean_std(x_0=8, y_idx=0, n_steps=512, batch_size=8)\n",
    "_ = model.naive_corr(y_idx=0, batch_size=100)\n",
    "_ = model.naive_ttest(y_idx=0, batch_size=100)\n",
    "_ = model.bsl_shap_corr(\n",
    "    x_0=8, y_idx=0, n_iter=2, x_0_batch_size=8, n_x=n_samples[0]//10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (label, filename)\n",
    "attributions = (\n",
    "    ('IGC', 'int_grad_corr.npz'),\n",
    "    ('IGaC', 'int_grad_auto.npz'),\n",
    "    ('IG mean', 'int_grad_mean.npz'),\n",
    "    ('IG SD', 'int_grad_std.npz'),\n",
    "    ('naive correlation', 'corr.npz'),\n",
    "    ('naive ttest', 'ttest.npz'),\n",
    "    ('BSC', 'bsl_shap_corr.npz'),\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1, 7, figsize=(14, 2),\n",
    "    gridspec_kw = {'top': 0.85, 'bottom': 0.01, 'left': 0.01, 'right': 0.99})\n",
    "\n",
    "for i, (label, filename) in enumerate(attributions):\n",
    "    attr = np.load(model.get_result_path(filename))['data'][0]\n",
    "    if label == 'naive ttest':\n",
    "        attr = (attr < 0.001)*1.0 - 0.5  # p-value < 0.001\n",
    "\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.annotate(\n",
    "        label, (0.5, 1.05), va='bottom', ha='center', xycoords='axes fraction')\n",
    "    v_max = 1.25 * np.quantile(np.abs(attr), 0.99)\n",
    "    ax.imshow(\n",
    "        attr, cmap='RdBu_r', vmin=-1.0*v_max, vmax=v_max,\n",
    "        extent=(-0.5, 0.5, -0.5, 0.5), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGC from trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igcsimulation.simulation_1v0 import Dataset\n",
    "\n",
    "# Experiments A, B, C, D (mask_name, imst_name, imst_kwargs)\n",
    "expe = ('comb_01', 'w_sum', None)\n",
    "#expe = ('ccat_01', 'max_mean_bin', None)\n",
    "#expe = ('ccat_02', 'max_sim_rand00_bin', {'probs': (0.0, 0.5)})\n",
    "#expe = ('ccat_03', 'argmax_sim_rand01_bin', {'permute': True})\n",
    "\n",
    "img_size = 64\n",
    "n_samples = (1000, 1000)\n",
    "# n_samples = (100000, 100000)  # Paper's values\n",
    "fft_slope = -1.2  # for natural images\n",
    "\n",
    "dataset = Dataset(expe[0], expe[1], img_size, n_samples, fft_slope, expe[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scalar statistics (experiments A, B, C)\n",
    "from igcsimulation.model_1v0 import Model\n",
    "\n",
    "# For categorical statistics (experiment D)\n",
    "# from igcsimulation.model_cat_1v0 import Model\n",
    "\n",
    "# ConvNeXt architecture\n",
    "parameters = {\n",
    "    'cvnx_sizes': (16, 32, 64, 128, 256),\n",
    "    'cvnx_stem_kernel': 2,\n",
    "    'lin_sizes': (128, 16),\n",
    "}\n",
    "\n",
    "# Simple multilayer perceptron \n",
    "# parameters = {\n",
    "#     'cvnx_sizes': None,\n",
    "#     'cvnx_stem_kernel': None,\n",
    "#     'lin_sizes': (256, 128, 64, 32, 16),\n",
    "# }\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "model = Model(\n",
    "    dataset, model_name='model_1v0_a100', trainable=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(n_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute IGC attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.int_grad_corr(x_0=8, y_idx=0, n_steps=64, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize IGC attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(2, 2),\n",
    "    gridspec_kw = {'top': 0.85, 'bottom': 0.01, 'left': 0.01, 'right': 0.99})\n",
    "\n",
    "attr = np.load(model.get_result_path('int_grad_corr.npz'))['data'][0]\n",
    "\n",
    "ax.axis('off')\n",
    "ax.annotate(\n",
    "    'IGC (model)', (0.5, 1.05), va='bottom', ha='center',\n",
    "    xycoords='axes fraction')\n",
    "v_max = 1.25 * np.quantile(np.abs(attr), 0.99)\n",
    "ax.imshow(\n",
    "    attr, cmap='RdBu_r', vmin=-1.0*v_max, vmax=v_max,\n",
    "    extent=(-0.5, 0.5, -0.5, 0.5), interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
